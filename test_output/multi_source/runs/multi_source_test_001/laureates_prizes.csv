id,name,gender,bornDate,bornCountry,bornCity,year,category,share,motivation,aff_org,aff_city,aff_country,data_source,title,authors,abstract,url,publication_date,publication_title,tags,collected_at
1,Wilhelm Conrad Röntgen,male,1845-03-27,Prussia (now Germany),Lennep (now Remscheid),1901.0,physics,1,"""in recognition of the extraordinary services he has rendered by the discovery of the remarkable rays subsequently named after him""",Munich University,Munich,Germany,nobel_prize,,,,,,,,
,,,,,,,,,,,,,semantic_scholar,TensorFlow: A system for large-scale machine learning,Martín Abadi; P. Barham; Jianmin Chen; Z. Chen; Andy Davis; J. Dean; M. Devin; S. Ghemawat; G. Irving; M. Isard; M. Kudlur; J. Levenberg; R. Monga; Sherry Moore; D. Murray; Benoit Steiner; P. Tucker; Vijay Vasudevan; Pete Warden; M. Wicke; Yuan Yu; Xiaoqiang Zhang,"TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous ""parameter server"" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",https://www.semanticscholar.org/paper/4954fa180728932959997a4768411ff9136aac81,,,,2025-11-01T21:05:10.269343
,,,,,,,,,,,,,semantic_scholar,Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms,Han Xiao; Kashif Rasul; Roland Vollgraf,"We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL",https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32,,,,2025-11-01T21:05:10.269357
,,,,,,,,,,,,,semantic_scholar,Lecture Notes: Optimization for Machine Learning,Elad Hazan,"Lecture notes on optimization for machine learning, derived from a course at
Princeton University and tutorials given in MLSS, Buenos Aires, as well as
Simons Foundation, Berkeley.",https://arxiv.org/abs/1909.03550v1,,,,2025-11-01T21:05:10.269361
,,,,,,,,,,,,,semantic_scholar,An Optimal Control View of Adversarial Machine Learning,Xiaojin Zhu,"I describe an optimal control view of adversarial machine learning, where the
dynamical system is the machine learner, the input are adversarial actions, and
the control costs are defined by the adversary's goals to do harm and be hard
to detect. This view encompasses many types of adversarial machine learning,
including test-item attacks, training-data poisoning, and adversarial reward
shaping. The view encourages adversarial machine learning researcher to utilize
advances in control theory and reinforcement learning.",https://arxiv.org/abs/1811.04422v1,,,,2025-11-01T21:05:10.269363
,,,,,,,,,,,,,semantic_scholar,Physics-informed machine learning,G. Karniadakis; I. Kevrekidis; Lu Lu; P. Perdikaris; Sifan Wang; Liu Yang,,https://www.semanticscholar.org/paper/53c9f3c34d8481adaf24df3b25581ccf1bc53f5c,,,,2025-11-01T21:05:10.269365
,,,,,,,,,,,,,semantic_scholar,"Minimax deviation strategies for machine learning and recognition with
  short learning samples",Michail Schlesinger; Evgeniy Vodolazskiy,"The article is devoted to the problem of small learning samples in machine
learning. The flaws of maximum likelihood learning and minimax learning are
looked into and the concept of minimax deviation learning is introduced that is
free of those flaws.",https://arxiv.org/abs/1707.04849v1,,,,2025-11-01T21:05:10.269367
,,,,,,,,,,,,,semantic_scholar,Machine learning with sklearn,Thomas P. Trappenberg,<,https://doi.org/10.1093/oso/9780198828044.003.0003,,,,2025-11-01T21:05:10.269369
,,,,,,,,,,,,,semantic_scholar,Optimization and Machine Learning,,,https://doi.org/10.1002/9781119902881,,,,2025-11-01T21:05:10.269371
,,,,,,,,,,,,,semantic_scholar,Why Use Automated Machine Learning?,Kai R. Larsen; Daniel S. Becker,<,https://doi.org/10.1093/oso/9780190941659.003.0001,,,,2025-11-01T21:05:10.269373
